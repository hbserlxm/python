## Lock和with给程序加锁
要在多线程的程序中使用可变对象，你需要使用`threading`库中的`Lock`对象，就像下边这个例子：

```python
import threading

class ShareCounter:
    '''
    A counter object that can be shared by multiple threads
    '''

    def __init__(self,initial_value=0):
        self._value = initial_value
        self._value_lock = threading.Lock()

    def incr(self,delta=1):
        '''
        Increment the counter with locking
        '''
        with self._value_lock:
            self._value += delta

    def decr(self,delta=1):
        '''
        Decrement the counter with locking
        '''
        with self._value_lock:
            self._value -= delta
```

Lock对象和with语句块一起使用可以起到互斥执行的作用，意思是每次只有一个线程可以执行with语句包含的代码块。with语句会在执行前自动获取锁在执行后自动释放锁。

## 为啥不用acquire和release
线程的调度本质上是不确定的，因此在多线程程序中错误的使用锁机制可能会导致随机数据的损坏或者其他的异常行为，我们称之为竞争条件，为了避免竞争条件，最好在临界资源进行操作的那部分代码使用锁，在一些老的python代码中，显式的获得锁和释放锁是很常见的。下面是上面例子的变种：
```python
import threading

class SharedCounter:
    '''
    A counter object that can be shared by multiple threads
    '''
    def __init__(self,initial_value=0):
        self._value = initial_value
        self._value_lock = threading.Lock()
        
    def incr(self,delta=1):
        '''
        Increment the counter with locking
        '''
        self._value_lock.acquire()
        self._value += delta
        self._value_lock.release()
        
    def decr(self,delta=1):
        '''
        Decrement the counter with locking
        '''
        self._value_lock.acquire()
        self._value -= delta
        self._value_lock.release()
```

相比于这种老式的方法，with的语句更优雅，也更不容易出错，特别是可能会出现忘记release锁或者在获得锁后程序异常（使用with语句的话，可以保证在这两情况下仍能释放锁）。为了避免出现死锁的情况，使用锁机制的程序应该设定每个线程一次只允许获得一个锁。如果说不能这样做的话，你就需要更高级的死锁来避免机制，会在12.5 章节介绍。

## 上面的是一个实例一把锁，下面的是所有实例只有一把锁（类锁）
在threading 库中还提供了其他的同步原语，比如`RLock`和`Semaphore`对象，根据以往的经验，这些原语只是用于一些特殊的情况，如果你只是简单的对可变对象进行锁定，那么就不该使用他们。一个RLock（可重入锁）可以被同一个线程多次获取，主要用来实现基于监测对象模式的锁定和同步。在使用这种锁的情况下，当锁被持有时，只有一个线程可以使用完整的函数或类中的方法，比如你可以实现一个这样的ShareCounter类：
```python
import threading

class ShareCounter:
    '''
    A counter object that can be shared by multiple threads.
    '''
    _lock = threading.RLock()

    def __init__(self,initial_value=0):
        self._value = initial_value

    def incr(self,delta=1):
        '''
        Increment the counter with locking
        '''
        with ShareCounter._lock:
            self._value += delta

    def decr(self,delta=1):
        '''
        Decrement the counter with locking
        '''
        with ShareCounter._lock:
            self.incr(-delta)
```

* 在上边这个例子中，没有对每一个实例中的可变对象加锁（没有在实例的初始化中设置锁），取而代之的是一个被所有实例锁共享的类级别的锁，这个锁用的同步类方法，具体来说就是，这个锁可以保证一直只有一个线程可以调用这个类方法。
* 不过与标准的锁不同的是，已经持有这个锁的的方法在使用这个锁的方法的时，无需再次获取锁，比如decr方法。
* 这种实现方法的一个特点是，无论这个类有多少的实例都只用这一个锁。因此在大量使用计数器的情况下，内存的效率会更高。
* 这样做也有一个缺点，就是在大量线程并频繁更新计数器时，会有争用锁的问题。

* 信号量Semaphore对象是一个建立在共享计数器的基础上的同步原语，如果说计数器不为0，with语句计数器减一，线程被允许执行。with语句执行结束后，计数器加一，如果计数器为0，线程被阻塞，直到其他线程将计数器加1。
* 尽管你可以在程序中像标准锁一样使用信号量来做线程同步，但是这种方法不被推荐，因为使用信号量为程序增加了复杂性会影响程序的性能。
* 相对简单的作为锁使用，信号量更适用于那些需要在线程之间引入信号或限制的程序，比如，in需要先限制一段代码的并发访问量，你可以想下面这样使用信号量完成：

```python
from threading import Semaphore
import  urllib.request

# At most,five threads allowed to run at once 
_fetch_url_sema = Semaphore(5)

def fetch_url(url):
    with _fetch_url_sema:
        return urllib.request.urlopen(url)
```

如果对线程同步原语的底层和实现感兴趣，可以参考操作系统相关的书籍，绝大多数都有提及。